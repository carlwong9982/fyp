{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd097ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist, cifar10, cifar100\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data shapes: (10000, 28, 28, 1) (10000, 10) (54000, 28, 28, 1) (54000, 10) (6000, 28, 28, 1) (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "(x, y), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "img_rows, img_cols, channels = 28, 28, 1\n",
    "num_classes = 10\n",
    "\n",
    "#process the data\n",
    "x, x_test = x / 255.0, x_test / 255.0\n",
    "\n",
    "x = x.reshape((-1, img_rows, img_cols, channels))\n",
    "x_test = x_test.reshape((-1, img_rows, img_cols, channels))\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#split training set, test set, attack set\n",
    "x_train, x_attack, y_train, y_attack = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "print(\"Data shapes:\", x_test.shape, y_test.shape, x_train.shape, y_train.shape, x_attack.shape, y_attack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 5s 2ms/step - loss: 0.0304 - accuracy: 0.7838 - val_loss: 0.0094 - val_accuracy: 0.9385\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0089 - accuracy: 0.9412 - val_loss: 0.0062 - val_accuracy: 0.9602\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0066 - accuracy: 0.9568 - val_loss: 0.0059 - val_accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0055 - accuracy: 0.9643 - val_loss: 0.0054 - val_accuracy: 0.9623\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0048 - accuracy: 0.9679 - val_loss: 0.0048 - val_accuracy: 0.9688\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9712 - val_loss: 0.0045 - val_accuracy: 0.9695\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0039 - accuracy: 0.9749 - val_loss: 0.0055 - val_accuracy: 0.9648\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9757 - val_loss: 0.0046 - val_accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0036 - accuracy: 0.9775 - val_loss: 0.0055 - val_accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0033 - accuracy: 0.9786 - val_loss: 0.0044 - val_accuracy: 0.9719\n",
      "INFO:tensorflow:Assets written to: model/victim_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu', input_shape=(img_rows, img_cols, channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "victim_model = create_model()\n",
    "victim_model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data = (x_test, y_test))\n",
    "victim_model.save('model/victim_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Base accuracy on regular images: [0.004416625946760178, 0.9718999862670898]\n"
     ]
    }
   ],
   "source": [
    "#testing model\n",
    "print(\"Base accuracy on regular images:\", victim_model.evaluate(x=x_test, y=y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction API\n",
    "def get_prediction(image):\n",
    "    return victim_model.predict(image).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect initial data\n",
    "x_attack_init_ind = random.sample(range(0, x_attack.shape[0]), 100)\n",
    "x_attack_init = x_attack[x_attack_init_ind]\n",
    "\n",
    "#Label initial data\n",
    "y_attack_init = []\n",
    "for image in x_attack_init:\n",
    "    y_attack_init.append(get_prediction(image.reshape(1, img_rows, img_cols, channels)))\n",
    "\n",
    "y_attack_init = tf.one_hot(y_attack_init, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0898 - accuracy: 0.1188 - val_loss: 0.0896 - val_accuracy: 0.1197\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.0891 - accuracy: 0.1668 - val_loss: 0.0894 - val_accuracy: 0.1852\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0882 - accuracy: 0.3073 - val_loss: 0.0891 - val_accuracy: 0.1972\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.0877 - accuracy: 0.2618 - val_loss: 0.0888 - val_accuracy: 0.1880\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.0866 - accuracy: 0.2522 - val_loss: 0.0882 - val_accuracy: 0.1678\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0855 - accuracy: 0.2316 - val_loss: 0.0869 - val_accuracy: 0.1860\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0842 - accuracy: 0.2373 - val_loss: 0.0853 - val_accuracy: 0.2192\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.0823 - accuracy: 0.3369 - val_loss: 0.0838 - val_accuracy: 0.2441\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.0793 - accuracy: 0.3758 - val_loss: 0.0815 - val_accuracy: 0.2971\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0767 - accuracy: 0.4135 - val_loss: 0.0785 - val_accuracy: 0.3950\n",
      "313/313 [==============================] - 0s 994us/step - loss: 0.0785 - accuracy: 0.3950\n",
      "Attack model accuracy: 0.395000\n"
     ]
    }
   ],
   "source": [
    "#Create attacker model architecture\n",
    "def create_attack_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu', input_shape=(img_rows, img_cols, channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "attack_model = create_attack_model()\n",
    "attack_model.fit(x_attack_init, y_attack_init, batch_size=32, epochs=10, validation_data = (x_test, y_test))\n",
    "print(\"Attack model accuracy: %f\" % (attack_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating adversarial example\n",
    "def adversarial_pattern(image, label, model):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.MSE(label, prediction)\n",
    "    \n",
    "    gradient = tape.gradient(loss, image)\n",
    "    \n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.0811 - accuracy: 0.3000 - val_loss: 0.0748 - val_accuracy: 0.4164\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.0773 - accuracy: 0.3650 - val_loss: 0.0722 - val_accuracy: 0.4659\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.0737 - accuracy: 0.4450 - val_loss: 0.0689 - val_accuracy: 0.4985\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.0709 - accuracy: 0.4850 - val_loss: 0.0635 - val_accuracy: 0.5922\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 54ms/step - loss: 0.0665 - accuracy: 0.5200 - val_loss: 0.0602 - val_accuracy: 0.5877\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.0625 - accuracy: 0.5050 - val_loss: 0.0552 - val_accuracy: 0.6288\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.0595 - accuracy: 0.5550 - val_loss: 0.0534 - val_accuracy: 0.6182\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.0564 - accuracy: 0.5500 - val_loss: 0.0508 - val_accuracy: 0.6454\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.0534 - accuracy: 0.6000 - val_loss: 0.0480 - val_accuracy: 0.6624\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.0504 - accuracy: 0.5950 - val_loss: 0.0488 - val_accuracy: 0.6606\n",
      "Dataset size: 200\n",
      "313/313 [==============================] - 0s 943us/step - loss: 0.0488 - accuracy: 0.6606\n",
      "Attack model accuracy: 0.660600\n",
      "Iteration: 2\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0673 - accuracy: 0.4850 - val_loss: 0.0489 - val_accuracy: 0.6527\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.0637 - accuracy: 0.5300 - val_loss: 0.0459 - val_accuracy: 0.7009\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.0603 - accuracy: 0.5625 - val_loss: 0.0479 - val_accuracy: 0.6790\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.0570 - accuracy: 0.6125 - val_loss: 0.0455 - val_accuracy: 0.7085\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.0544 - accuracy: 0.6100 - val_loss: 0.0450 - val_accuracy: 0.6940\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.0523 - accuracy: 0.6600 - val_loss: 0.0445 - val_accuracy: 0.6945\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.0498 - accuracy: 0.6750 - val_loss: 0.0444 - val_accuracy: 0.6819\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.0474 - accuracy: 0.6800 - val_loss: 0.0415 - val_accuracy: 0.7210\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.0451 - accuracy: 0.7100 - val_loss: 0.0403 - val_accuracy: 0.7267\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.0423 - accuracy: 0.7275 - val_loss: 0.0408 - val_accuracy: 0.7184\n",
      "Dataset size: 400\n",
      "313/313 [==============================] - 0s 908us/step - loss: 0.0408 - accuracy: 0.7184\n",
      "Attack model accuracy: 0.718400\n",
      "Iteration: 3\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.6000 - val_loss: 0.0432 - val_accuracy: 0.6921\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0539 - accuracy: 0.6450 - val_loss: 0.0428 - val_accuracy: 0.6994\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0492 - accuracy: 0.6812 - val_loss: 0.0406 - val_accuracy: 0.7260\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.6975 - val_loss: 0.0416 - val_accuracy: 0.7045\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0447 - accuracy: 0.7088 - val_loss: 0.0394 - val_accuracy: 0.7272\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0426 - accuracy: 0.7387 - val_loss: 0.0374 - val_accuracy: 0.7398\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 0.7225 - val_loss: 0.0396 - val_accuracy: 0.7248\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0385 - accuracy: 0.7638 - val_loss: 0.0401 - val_accuracy: 0.7155\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0364 - accuracy: 0.7750 - val_loss: 0.0355 - val_accuracy: 0.7529\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0338 - accuracy: 0.7912 - val_loss: 0.0362 - val_accuracy: 0.7443\n",
      "Dataset size: 800\n",
      "313/313 [==============================] - 0s 984us/step - loss: 0.0362 - accuracy: 0.7443\n",
      "Attack model accuracy: 0.744300\n"
     ]
    }
   ],
   "source": [
    "#Create synthetic example\n",
    "def train_attack_model(iteration, eps):\n",
    "    counter = 1\n",
    "    x_attack_set = x_attack_init\n",
    "    y_attack_set = y_attack_init\n",
    "    \n",
    "    while True:\n",
    "        print(\"Iteration: %d\" % (counter))\n",
    "\n",
    "        for i in range(x_attack_set.shape[0]):\n",
    "            image = x_attack_set[i]\n",
    "            image_label = y_attack_set[i]\n",
    "            perturbations = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), image_label, attack_model).numpy()\n",
    "            adversarial = image + perturbations * eps\n",
    "            x_attack_set = np.append(x_attack_set, adversarial, axis = 0)\n",
    "\n",
    "        #Label new dataset\n",
    "        y_attack_set = []\n",
    "        for image in x_attack_set:\n",
    "            y_attack_set.append(get_prediction(image.reshape(1, img_rows, img_cols, channels)))\n",
    "\n",
    "        y_attack_set = tf.one_hot(y_attack_set, 10)\n",
    "\n",
    "        #train the attack model with new dataset\n",
    "        attack_model.fit(x_attack_set, y_attack_set, batch_size=32, epochs=10, validation_data = (x_test, y_test))\n",
    "\n",
    "        #evluate the attack model\n",
    "        print(\"Dataset size: %d\" % (x_attack_set.shape[0]))\n",
    "        print(\"Attack model accuracy: %f\" % (attack_model.evaluate(x_test, y_test)[1]))\n",
    "\n",
    "        if counter == iteration:\n",
    "            break\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "train_attack_model(3, 64/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}